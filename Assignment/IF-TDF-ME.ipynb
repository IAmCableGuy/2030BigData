{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all libraries required in the code\n",
    "from __future__ import print_function, division\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import nltk\n",
    "#nltk.download('punkt')\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "import math\n",
    "from collections import Counter\n",
    "#nltk.download('stopwords')\n",
    "import pprint \n",
    "pp = pprint.PrettyPrinter(indent=4)\n",
    "%matplotlib inline\n",
    "\n",
    "# read in the data from the supplied assignment file and check input via table \n",
    "df = pd.read_csv(\"data_assignment.csv\")\n",
    "\n",
    "def open_data_file(fileName):\n",
    "    opened_file = open(fileName)\n",
    "    from csv import reader\n",
    "    readFile = reader(opened_file)\n",
    "    data = list(readFile)\n",
    "\n",
    "    return data\n",
    "\n",
    "assignData = open_data_file(fileName = \"data_assignment.csv\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your favourite job sector/sub-sector, then use TF/IDF to extract important keywords. \n",
    "# Visualise them in word cloud # chart (hint: you can use the online tool https://wordart.com/create or similar websites\n",
    "\n",
    "it_documents = df.loc[df.Classification == \"Information & Communication Technology\"]\n",
    "original_documents = it_documents[\"Requirement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english', max_features=500)\n",
    "\n",
    "features = tfidf.fit(original_documents)\n",
    "corpus_tf_idf = tfidf.transform(original_documents) \n",
    "\n",
    "sum_words = corpus_tf_idf.sum(axis=0)\n",
    "words_freq = [(word, sum_words[0, idx]) for word, idx in tfidf.vocabulary_.items()]\n",
    "#print(sorted(words_freq, key = lambda x: x[1], reverse=True)[:500])\n",
    "last500 = (sorted(words_freq, key = lambda x: x[1], reverse=True)[:500])\n",
    "#print('team', corpus_tf_idf[1, features.vocabulary_['team']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the last500 list of words to a dictionary\n",
    "convertList = dict(last500)\n",
    "\n",
    "#convert the dictionary to a dataframe\n",
    "df500 = pd.DataFrame(list(convertList.items()),columns = ['Word','TD-IDF Value']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df500.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the 500 words in the dataframe to a csv file so we can import into WordArt website\n",
    "df500.to_csv('wordArt1.csv',header=False, index=False)\n",
    "df500.to_csv('wordArt3.csv',header=True, index=False)\n",
    "df500['Word'].to_csv('wordArt2.csv',header=False, index=False)"
   ]
  }
 ]
}